{
 "cells": [
  {
   "cell_type": "raw",
   "id": "deb7fea7-77af-4656-a433-5ea16ec02dc8",
   "metadata": {},
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e824cccd-024a-40d8-9747-41080635bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_millsongdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1574b10-a460-4e46-93dc-f94af98ff3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abac8281-768b-4b22-9f64-f48370d39f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec0e7cbe-837b-4ea1-bef4-1fcbbc7d546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(100).drop('link', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9923c8a5-c9d2-4fe2-9646-26b8bc834273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Purple</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>you're sweeter than the morning  \\r when the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neil Sedaka</td>\n",
       "      <td>Darei 10 Anni</td>\n",
       "      <td>darei dieci anni della vita mia  \\r per rivede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenny Rogers</td>\n",
       "      <td>Life Is Good, Love Is Better</td>\n",
       "      <td>life is a hustle, every day struggle  \\r pushi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whitney Houston</td>\n",
       "      <td>Jesus Loves Me</td>\n",
       "      <td>yes jesus loves me for the bible tells me so  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reo Speedwagon</td>\n",
       "      <td>Give Me A Ride</td>\n",
       "      <td>give me a ride on your roller coaster  \\r give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist                          song  \\\n",
       "0      Deep Purple                       Hold On   \n",
       "1      Neil Sedaka                 Darei 10 Anni   \n",
       "2     Kenny Rogers  Life Is Good, Love Is Better   \n",
       "3  Whitney Houston                Jesus Loves Me   \n",
       "4   Reo Speedwagon                Give Me A Ride   \n",
       "\n",
       "                                                text  \n",
       "0  you're sweeter than the morning  \\r when the s...  \n",
       "1  darei dieci anni della vita mia  \\r per rivede...  \n",
       "2  life is a hustle, every day struggle  \\r pushi...  \n",
       "3  yes jesus loves me for the bible tells me so  ...  \n",
       "4  give me a ride on your roller coaster  \\r give...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522d0ce-396a-4c4b-9e8d-2ef8cd781529",
   "metadata": {},
   "source": [
    "Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6052eac-d039-4a93-8a38-8e380657825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].str.lower().replace(r'^\\w\\s', ' ').replace(r'\\n', ' ', regex =True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af4c9e3e-bd0c-4353-acfa-b59e802cb4f0",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84d8bdb5-218b-4b0f-962a-d73d8a6e2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f2aa94a-0943-4b62-aa43-0ca0e2eee7c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1134587942.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[105], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install nltk\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "937c09cc-b142-4f9d-b5da-2c77597ebfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35d8e61f-25e9-45a5-a9ac-0afcdbec280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ef12075-81db-4436-8be2-e70b68a9058e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (522149543.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[108], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def token(txt)\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def token(txt)\n",
    "    token = nltk.word_tokenize(txt)\n",
    "    a =[stemmer.stem(w) for w in token]\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c5de6c23-f34b-4026-8911-e8842edab749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kishanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e5223368-3d34-4e8e-95e3-b11e9fc298b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kishanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Kishanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "312a4d27-23c3-49e9-955b-135f1ced598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(txt):\n",
    "    token = nltk.word_tokenize(txt)\n",
    "    a =[stemmer.stem(w) for w in token]\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e14ca99-6ffe-4dd0-876c-08d053a97187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are beauti , beauti'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(\"you are beautiful, beauty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68b35a70-bd66-4816-8377-b28fde1707e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     you 're sweeter than the morn when the sun is ...\n",
       "1     darei dieci anni della vita mia per rivederti ...\n",
       "2     life is a hustl , everi day struggl push your ...\n",
       "3     ye jesu love me for the bibl tell me so jesu l...\n",
       "4     give me a ride on your roller coaster give me ...\n",
       "                            ...                        \n",
       "95    ich oeffn da fenster seh , wie roter staub sic...\n",
       "96    i wa down in georgia noth wa as real as the st...\n",
       "97    you know your favorit old pair of shoesth one ...\n",
       "98    it 's earli morn the sun come out last night w...\n",
       "99    there is no time to discuss or debat what is r...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: token(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8379eb9f-9031-46a8-8663-8bfa3f825ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9ae4601-0b72-44ca-8cd4-eeeffe07cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a0500144-c775-4c4f-a83d-20481fffd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word', stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11e6f92d-d37c-46ab-8d73-4d1e1e1f9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word', stop_words='english', max_features=1000)\n",
    "matrix = tfid.fit_transform(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "70d33e28-76dc-408a-a328-e9b5e9fc8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (2.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\kishanth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dddcb71f-6786-4378-b0c8-0469bc4974f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f71ef-8010-4c0e-ac0b-0e8db03931ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d3580156-52bd-4c64-b3cd-c840f5b582d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     you 're sweeter than the morn when the sun is ...\n",
       "1     darei dieci anni della vita mia per rivederti ...\n",
       "2     life is a hustl , everi day struggl push your ...\n",
       "3     ye jesu love me for the bibl tell me so jesu l...\n",
       "4     give me a ride on your roller coaster give me ...\n",
       "                            ...                        \n",
       "95    ich oeffn da fenster seh , wie roter staub sic...\n",
       "96    i wa down in georgia noth wa as real as the st...\n",
       "97    you know your favorit old pair of shoesth one ...\n",
       "98    it 's earli morn the sun come out last night w...\n",
       "99    there is no time to discuss or debat what is r...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: token(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "83ad3159-b62d-4734-8edc-504ee41001a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2361befa-7812-4738-b6f5-3a4ba69c02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word', stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1844be4c-8967-439a-b4fa-a12c3842978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=tfid.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0c023ce0-04c5-4a1c-a5fc-a278bccc3398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 5523 stored elements and shape (100, 2538)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c52a8d64-0c86-46ae-ad10-9f9478a03075",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar=cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ad9d762-399e-4e10-93ec-d458868b0fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.08513857, 0.01379319, 0.07501384,\n",
       "       0.03367544, 0.02644108, 0.02273825, 0.08167955, 0.05820021,\n",
       "       0.06286039, 0.0192711 , 0.0061997 , 0.04775109, 0.03567731,\n",
       "       0.03346368, 0.0711211 , 0.03470765, 0.02944399, 0.1098532 ,\n",
       "       0.03071414, 0.04653981, 0.06515365, 0.07725756, 0.04034841,\n",
       "       0.01470069, 0.07568233, 0.04889683, 0.1974241 , 0.12324727,\n",
       "       0.10435045, 0.020476  , 0.01067632, 0.02802204, 0.06876865,\n",
       "       0.08162772, 0.08382184, 0.02407206, 0.12675863, 0.05717229,\n",
       "       0.01890023, 0.02907512, 0.08071823, 0.09778887, 0.03756533,\n",
       "       0.04278655, 0.16484838, 0.01258116, 0.02325047, 0.04758007,\n",
       "       0.0143697 , 0.0946297 , 0.05387326, 0.02445098, 0.0197172 ,\n",
       "       0.        , 0.08724013, 0.04299399, 0.00654553, 0.00536352,\n",
       "       0.05531172, 0.0497682 , 0.06131633, 0.00506494, 0.17256744,\n",
       "       0.09545847, 0.00768747, 0.04495792, 0.04257339, 0.03233774,\n",
       "       0.03291578, 0.01901155, 0.01563258, 0.03237044, 0.04166715,\n",
       "       0.02840904, 0.05734638, 0.02792092, 0.01349099, 0.02721245,\n",
       "       0.063825  , 0.06431796, 0.01106302, 0.04418156, 0.04214692,\n",
       "       0.01329631, 0.08723846, 0.04924678, 0.05931751, 0.01020586,\n",
       "       0.09180743, 0.02419285, 0.00741924, 0.02836867, 0.10001043,\n",
       "       0.        , 0.00727943, 0.14796221, 0.04598653, 0.00437552])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d08efdd4-12a9-4eb0-99e0-f37440162c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df[df['song'] == 'Darei 10 Anni'].index[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0cf6d016-eb08-491d-9b75-b4fc50a0a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hold On' 'Darei 10 Anni' 'Life Is Good, Love Is Better' 'Jesus Loves Me'\n",
      " 'Give Me A Ride' 'Parallel Universe' 'Heidi Is A Headcase'\n",
      " 'Carolina In My Mind' 'Butterflies' 'Drive My Car' \"I'm Already There\"\n",
      " 'Burning Feet' 'Lucy In The Subway' 'Camouflage' 'Child Of Midnight'\n",
      " 'Not To Touch The Earth' 'Kiss That Frog' 'Away In A Manger' 'Grow Up'\n",
      " 'Ann' 'Funky Beat' 'Perfect Strangers' \"I Can't Get Nowhere With You\"\n",
      " 'A Goodbye Joke' 'Gettin Paid' 'Red Rover' 'How About You' 'No Contract'\n",
      " 'Human' \"Can't Stop Thinking About Love\" 'Getting High On The Down Low'\n",
      " 'Pittsburgh, Pennsylvania' 'Better Off Without You' 'Riding Alone'\n",
      " 'All Of Me' 'December' 'Boogie On Reggae Woman - Phish' 'Scent Of A Mule'\n",
      " 'Sail The Rivers' 'Not Coming Home' 'Falling Off The Face Of The Earth'\n",
      " 'Perform This Way' \"Small Y'all\" \"It's You\" 'I Miss A Lot Of Trains'\n",
      " 'Busy Signal' 'Love Is War' 'Lost Stars' 'Born In Puerto Rico'\n",
      " 'The Perfect Fan' \"It's The Hard-Knock Life\" 'Everybody I Love You'\n",
      " 'Ooh I Like Your Loving' 'Andy' 'Caravan' 'Effigy' 'Somebody Needs You'\n",
      " 'Back To School Again' 'Holiness Is Right' 'Praise You' 'Stay With Me'\n",
      " 'Honey Bee' 'First Day Of Spring' 'Breaking The Law' 'One Of These Days'\n",
      " 'Strong' 'Angry Hills' \"Smokin' Room\" 'Old Pictures'\n",
      " \"The Kids Aren't Alright\" 'Graffiti' 'Heart Like Heaven'\n",
      " 'Sight For Sore Eyes' 'Children In Heat' 'Die Die My Darling'\n",
      " 'Fake Plastic Trees' \"Let's Submerge\" 'A New Argentina'\n",
      " 'Out Of The Cradle' 'The Sun And The Moon And The Stars' 'Let It Pour'\n",
      " 'Nasty Naughty Boy' 'Better Than Anything'\n",
      " \"Don't Let The Stars Get In Your Eyes\" 'Here Comes The Sun'\n",
      " 'Spanish Harlem' 'Who Do You Love' 'Birthday' 'One' 'Carol Of The Bells'\n",
      " \"Everybody's Rockin'\" \"Can't Take The Hurt Anymore\"\n",
      " \"It Don't Mean A Thing\" 'Heaven Sent' 'Life Goes On'\n",
      " 'Der Rhythmus Der Hitze' 'Summer Cannibals' 'Jailbreak' 'Hurricane 2000'\n",
      " 'Orphans Of Wealth']\n"
     ]
    }
   ],
   "source": [
    "print(df['song'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce765e2-71c6-4eff-9bfa-315a93dd2c3f",
   "metadata": {},
   "source": [
    "recommender function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d117ac6b-85fd-415f-9bba-650a2e1fda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(song_name):\n",
    "    idx = df[df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(similar[idx])), reverse=True, key = lambda x:x[1])\n",
    "    song=[]\n",
    "    for s_id in distance[1:50]:\n",
    "        song.append(df.iloc[s_id[0]].song)\n",
    "        return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f2eb90da-e205-4071-bf5c-3ab44383e020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Butterflies']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender(\"Jailbreak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "82479b46-3f8f-4694-a822-8bb32f2a137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Patti Smith</td>\n",
       "      <td>Summer Cannibals</td>\n",
       "      <td>i was down in georgia  \\r nothing was as real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bon Jovi</td>\n",
       "      <td>Jailbreak</td>\n",
       "      <td>you know your favorite old pair of shoesthe on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scorpions</td>\n",
       "      <td>Hurricane 2000</td>\n",
       "      <td>it's early morning  \\r the sun comes out  \\r l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Don McLean</td>\n",
       "      <td>Orphans Of Wealth</td>\n",
       "      <td>there is no time to discuss or debate  \\r what...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist               song  \\\n",
       "96  Patti Smith   Summer Cannibals   \n",
       "97     Bon Jovi          Jailbreak   \n",
       "98    Scorpions     Hurricane 2000   \n",
       "99   Don McLean  Orphans Of Wealth   \n",
       "\n",
       "                                                 text  \n",
       "96  i was down in georgia  \\r nothing was as real ...  \n",
       "97  you know your favorite old pair of shoesthe on...  \n",
       "98  it's early morning  \\r the sun comes out  \\r l...  \n",
       "99  there is no time to discuss or debate  \\r what...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4e895a38-6e56-48d2-909f-16d28a2453f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "837888a8-0e28-4515-90ac-8e0c176cb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similar, open(\"similarity\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "290a4b59-2a0e-4e46-91db-445c804fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(\"df\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8012d302-2d3c-487f-944e-909c4ff8cb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.pkl file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Create a simple DataFrame (replace this with your actual data)\n",
    "df = pd.DataFrame({\n",
    "    'song': ['Song 1', 'Song 2', 'Song 3'],\n",
    "    'artist': ['Artist A', 'Artist B', 'Artist C'],\n",
    "    'duration': [200, 180, 210]\n",
    "})\n",
    "\n",
    "# Save DataFrame to pickle file\n",
    "with open('df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(\"df.pkl file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb09c496-7b52-4dfd-918e-ca44af080c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3fea1b51-c2b1-46b5-a722-8c12d3ea2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity.pkl file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Example data - this would be your similarity data\n",
    "similarity_matrix = np.array([[1, 0.8, 0.6], [0.8, 1, 0.7], [0.6, 0.7, 1]])\n",
    "\n",
    "# Save the similarity matrix to a pickle file\n",
    "with open('similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)\n",
    "\n",
    "print(\"similarity.pkl file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2b4c3cf3-e11f-4683-8e12-bd950b13e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('similarity.pkl', 'rb') as f:\n",
    "    similarity = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c356d-81e6-408b-a6fc-c975560aa4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
